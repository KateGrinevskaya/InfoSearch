{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 1. Индекс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гриневская Катя, БКЛ182"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я ориентировалась на то что, что в папке, в которой лежит этот код, также находится папка `friends-data`, в которой лежат папки по сезонам. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "mystem = Mystem() \n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция препроцессинга данных. Включите туда лемматизацию, приведение к одному регистру, удаление пунктуации и стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preproc(dir_name):\n",
    "    corpus = []\n",
    "    curr_dir = os.getcwd()\n",
    "    files_dir = os.path.join(curr_dir, dir_name)\n",
    "    for root, dirs, files in os.walk(files_dir):\n",
    "        for name in files:\n",
    "            fpath = os.path.join(root, name)\n",
    "            with open(fpath, 'r', encoding='utf-8') as f:\n",
    "                text = f.read().replace('\\n\\n', ' ').replace('\\n', ' ')\n",
    "                text = re.sub(r'\\d+|[a-zA-Z]+', ' ', text)\n",
    "                tokens = mystem.lemmatize(text.lower())\n",
    "                puncts = '''!@#$%^&\"*()«»_+.—!!!\\,|/,...:;?-!.'''\n",
    "                tokens = [token for token in tokens if token not in russian_stopwords\\\n",
    "                          and token.isalpha()]\n",
    "                clean_text = \" \".join(tokens)\n",
    "                corpus.append(clean_text)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция индексирования данных. На выходе создает обратный индекс, он же матрица Term-Document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word')\n",
    "def get_index(corpus):\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    df = pd.DataFrame(X.todense(), columns=vectorizer.get_feature_names())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    corpus = get_preproc('friends-data')\n",
    "    df = get_index(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a) какое слово является самым частотным?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "это\n"
     ]
    }
   ],
   "source": [
    "df.loc['TOTAL'] = df.sum()\n",
    "words_dict = {}\n",
    "for col in df.columns:\n",
    "    words_dict[col] = df[col]['TOTAL']\n",
    "print(Counter(words_dict).most_common(1)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b) какое самым редким"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ящерица\n"
     ]
    }
   ],
   "source": [
    "print(Counter(words_dict).most_common()[-1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c) какой набор слов есть во всех документах коллекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['весь', 'давать', 'думать', 'знать', 'мочь', 'просто', 'сказать', 'хотеть', 'это']\n"
     ]
    }
   ],
   "source": [
    "words_all_docs = []\n",
    "for col in df.columns:\n",
    "    if 0 not in df[col].to_list():\n",
    "        words_all_docs.append(col)\n",
    "print(words_all_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### d) кто из главных героев статистически самый популярный (упоминается чаще всего)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Росс\n"
     ]
    }
   ],
   "source": [
    "names = {'моника': 0, 'рэйчел': 0, 'чендлер': 0, 'фиби': 0, 'росс': 0,\n",
    "           'джоуи': 0, 'мон': 0, 'рейч': 0, 'чэндлер': 0, 'чен': 0, 'фибс': 0,\n",
    "           'джои': 0, 'джо': 0}\n",
    "persons = {}\n",
    "#persons = {'моника': 0, 'рэйчел': 0, 'чендлер': 0, 'фиби': 0, 'росс': 0,\n",
    "           #'джоуи': 0}\n",
    "for name in names.keys():\n",
    "    try:\n",
    "        names[name] = df[name]['TOTAL']\n",
    "    except:\n",
    "        continue\n",
    "persons['моника'] = names['моника'] + names['мон']\n",
    "persons['рэйчел'] = names['рэйчел'] + names['рейч']\n",
    "persons['чендлер'] = names['чендлер'] + names['чэндлер'] + names['чен']\n",
    "persons['фиби'] = names['фиби'] + names['фибс']\n",
    "persons['росс'] = names['росс']\n",
    "persons['джоуи'] = names['джоуи'] + names['джои'] + names['джо']\n",
    "print(Counter(persons).most_common(1)[0][0].title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
